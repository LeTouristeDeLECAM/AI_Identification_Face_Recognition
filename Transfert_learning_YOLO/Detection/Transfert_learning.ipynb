{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.ultralytics.com/yolov5/tutorials/transfer_learning_with_frozen_layers/#before-you-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1611240  ultralytics.nn.modules.head.Classify         [256, 1000]                   \n",
      "YOLOv8n-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1   1611240  ultralytics.nn.modules.head.Classify         [256, 1000]                   \n",
      "YOLOv8n-cls summary: 99 layers, 2719288 parameters, 2719288 gradients, 4.4 GFLOPs\n",
      "Transferred 158/158 items from pretrained weights\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model for detection\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model\n",
    "\n",
    "\n",
    "\n",
    "# Load a model for classification\n",
    "# model = YOLO('yolov8n-cls.yaml')  # build a new model from YAML\n",
    "# model = YOLO('yolov8n-cls.pt')  # load a pretrained model (recommended for training)\n",
    "# model = YOLO('yolov8n-cls.yaml').load('yolov8n-cls.pt')  # build from YAML and transfer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freezing model.model.0.conv.weight\n",
      "freezing model.model.0.bn.weight\n",
      "freezing model.model.0.bn.bias\n",
      "freezing model.model.1.conv.weight\n",
      "freezing model.model.1.bn.weight\n",
      "freezing model.model.1.bn.bias\n",
      "freezing model.model.2.cv1.conv.weight\n",
      "freezing model.model.2.cv1.bn.weight\n",
      "freezing model.model.2.cv1.bn.bias\n",
      "freezing model.model.2.cv2.conv.weight\n",
      "freezing model.model.2.cv2.bn.weight\n",
      "freezing model.model.2.cv2.bn.bias\n",
      "freezing model.model.2.m.0.cv1.conv.weight\n",
      "freezing model.model.2.m.0.cv1.bn.weight\n",
      "freezing model.model.2.m.0.cv1.bn.bias\n",
      "freezing model.model.2.m.0.cv2.conv.weight\n",
      "freezing model.model.2.m.0.cv2.bn.weight\n",
      "freezing model.model.2.m.0.cv2.bn.bias\n",
      "freezing model.model.3.conv.weight\n",
      "freezing model.model.3.bn.weight\n",
      "freezing model.model.3.bn.bias\n",
      "freezing model.model.4.cv1.conv.weight\n",
      "freezing model.model.4.cv1.bn.weight\n",
      "freezing model.model.4.cv1.bn.bias\n",
      "freezing model.model.4.cv2.conv.weight\n",
      "freezing model.model.4.cv2.bn.weight\n",
      "freezing model.model.4.cv2.bn.bias\n",
      "freezing model.model.4.m.0.cv1.conv.weight\n",
      "freezing model.model.4.m.0.cv1.bn.weight\n",
      "freezing model.model.4.m.0.cv1.bn.bias\n",
      "freezing model.model.4.m.0.cv2.conv.weight\n",
      "freezing model.model.4.m.0.cv2.bn.weight\n",
      "freezing model.model.4.m.0.cv2.bn.bias\n",
      "freezing model.model.4.m.1.cv1.conv.weight\n",
      "freezing model.model.4.m.1.cv1.bn.weight\n",
      "freezing model.model.4.m.1.cv1.bn.bias\n",
      "freezing model.model.4.m.1.cv2.conv.weight\n",
      "freezing model.model.4.m.1.cv2.bn.weight\n",
      "freezing model.model.4.m.1.cv2.bn.bias\n",
      "freezing model.model.5.conv.weight\n",
      "freezing model.model.5.bn.weight\n",
      "freezing model.model.5.bn.bias\n",
      "freezing model.model.6.cv1.conv.weight\n",
      "freezing model.model.6.cv1.bn.weight\n",
      "freezing model.model.6.cv1.bn.bias\n",
      "freezing model.model.6.cv2.conv.weight\n",
      "freezing model.model.6.cv2.bn.weight\n",
      "freezing model.model.6.cv2.bn.bias\n",
      "freezing model.model.6.m.0.cv1.conv.weight\n",
      "freezing model.model.6.m.0.cv1.bn.weight\n",
      "freezing model.model.6.m.0.cv1.bn.bias\n",
      "freezing model.model.6.m.0.cv2.conv.weight\n",
      "freezing model.model.6.m.0.cv2.bn.weight\n",
      "freezing model.model.6.m.0.cv2.bn.bias\n",
      "freezing model.model.6.m.1.cv1.conv.weight\n",
      "freezing model.model.6.m.1.cv1.bn.weight\n",
      "freezing model.model.6.m.1.cv1.bn.bias\n",
      "freezing model.model.6.m.1.cv2.conv.weight\n",
      "freezing model.model.6.m.1.cv2.bn.weight\n",
      "freezing model.model.6.m.1.cv2.bn.bias\n",
      "freezing model.model.7.conv.weight\n",
      "freezing model.model.7.bn.weight\n",
      "freezing model.model.7.bn.bias\n",
      "freezing model.model.8.cv1.conv.weight\n",
      "freezing model.model.8.cv1.bn.weight\n",
      "freezing model.model.8.cv1.bn.bias\n",
      "freezing model.model.8.cv2.conv.weight\n",
      "freezing model.model.8.cv2.bn.weight\n",
      "freezing model.model.8.cv2.bn.bias\n",
      "freezing model.model.8.m.0.cv1.conv.weight\n",
      "freezing model.model.8.m.0.cv1.bn.weight\n",
      "freezing model.model.8.m.0.cv1.bn.bias\n",
      "freezing model.model.8.m.0.cv2.conv.weight\n",
      "freezing model.model.8.m.0.cv2.bn.weight\n",
      "freezing model.model.8.m.0.cv2.bn.bias\n",
      "freezing model.model.9.conv.conv.weight\n",
      "freezing model.model.9.conv.bn.weight\n",
      "freezing model.model.9.conv.bn.bias\n",
      "freezing model.model.9.linear.weight\n",
      "freezing model.model.9.linear.bias\n"
     ]
    }
   ],
   "source": [
    " # Freeze\n",
    "freeze = 184\n",
    "freeze = [f'model.{x}.' for x in range(freeze)]  # layers to freeze\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = True  # train all layers\n",
    "    if any(x in k for x in freeze):\n",
    "        print(f'freezing {k}')\n",
    "        v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.0.conv.weight\n",
      "model.model.0.bn.weight\n",
      "model.model.0.bn.bias\n",
      "model.model.1.conv.weight\n",
      "model.model.1.bn.weight\n",
      "model.model.1.bn.bias\n",
      "model.model.2.cv1.conv.weight\n",
      "model.model.2.cv1.bn.weight\n",
      "model.model.2.cv1.bn.bias\n",
      "model.model.2.cv2.conv.weight\n",
      "model.model.2.cv2.bn.weight\n",
      "model.model.2.cv2.bn.bias\n",
      "model.model.2.m.0.cv1.conv.weight\n",
      "model.model.2.m.0.cv1.bn.weight\n",
      "model.model.2.m.0.cv1.bn.bias\n",
      "model.model.2.m.0.cv2.conv.weight\n",
      "model.model.2.m.0.cv2.bn.weight\n",
      "model.model.2.m.0.cv2.bn.bias\n",
      "model.model.3.conv.weight\n",
      "model.model.3.bn.weight\n",
      "model.model.3.bn.bias\n",
      "model.model.4.cv1.conv.weight\n",
      "model.model.4.cv1.bn.weight\n",
      "model.model.4.cv1.bn.bias\n",
      "model.model.4.cv2.conv.weight\n",
      "model.model.4.cv2.bn.weight\n",
      "model.model.4.cv2.bn.bias\n",
      "model.model.4.m.0.cv1.conv.weight\n",
      "model.model.4.m.0.cv1.bn.weight\n",
      "model.model.4.m.0.cv1.bn.bias\n",
      "model.model.4.m.0.cv2.conv.weight\n",
      "model.model.4.m.0.cv2.bn.weight\n",
      "model.model.4.m.0.cv2.bn.bias\n",
      "model.model.4.m.1.cv1.conv.weight\n",
      "model.model.4.m.1.cv1.bn.weight\n",
      "model.model.4.m.1.cv1.bn.bias\n",
      "model.model.4.m.1.cv2.conv.weight\n",
      "model.model.4.m.1.cv2.bn.weight\n",
      "model.model.4.m.1.cv2.bn.bias\n",
      "model.model.5.conv.weight\n",
      "model.model.5.bn.weight\n",
      "model.model.5.bn.bias\n",
      "model.model.6.cv1.conv.weight\n",
      "model.model.6.cv1.bn.weight\n",
      "model.model.6.cv1.bn.bias\n",
      "model.model.6.cv2.conv.weight\n",
      "model.model.6.cv2.bn.weight\n",
      "model.model.6.cv2.bn.bias\n",
      "model.model.6.m.0.cv1.conv.weight\n",
      "model.model.6.m.0.cv1.bn.weight\n",
      "model.model.6.m.0.cv1.bn.bias\n",
      "model.model.6.m.0.cv2.conv.weight\n",
      "model.model.6.m.0.cv2.bn.weight\n",
      "model.model.6.m.0.cv2.bn.bias\n",
      "model.model.6.m.1.cv1.conv.weight\n",
      "model.model.6.m.1.cv1.bn.weight\n",
      "model.model.6.m.1.cv1.bn.bias\n",
      "model.model.6.m.1.cv2.conv.weight\n",
      "model.model.6.m.1.cv2.bn.weight\n",
      "model.model.6.m.1.cv2.bn.bias\n",
      "model.model.7.conv.weight\n",
      "model.model.7.bn.weight\n",
      "model.model.7.bn.bias\n",
      "model.model.8.cv1.conv.weight\n",
      "model.model.8.cv1.bn.weight\n",
      "model.model.8.cv1.bn.bias\n",
      "model.model.8.cv2.conv.weight\n",
      "model.model.8.cv2.bn.weight\n",
      "model.model.8.cv2.bn.bias\n",
      "model.model.8.m.0.cv1.conv.weight\n",
      "model.model.8.m.0.cv1.bn.weight\n",
      "model.model.8.m.0.cv1.bn.bias\n",
      "model.model.8.m.0.cv2.conv.weight\n",
      "model.model.8.m.0.cv2.bn.weight\n",
      "model.model.8.m.0.cv2.bn.bias\n",
      "model.model.9.conv.conv.weight\n",
      "model.model.9.conv.bn.weight\n",
      "model.model.9.conv.bn.bias\n",
      "model.model.9.linear.weight\n",
      "model.model.9.linear.bias\n",
      "longeur :  80\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for k, v in model.named_parameters():\n",
    "    print(k)\n",
    "    i+=1\n",
    "\n",
    "print (\"longeur : \",i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.221 available  Update with 'pip install -U ultralytics'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.207  Python-3.9.2 torch-2.1.0+cpu CPU (Intel Core(TM) i5-7300U 2.60GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.yaml, data=transfertEye.yaml, epochs=2, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train9, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train9\n",
      "\n",
      "Dataset not found , missing path C:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\labeling_test\\datasets\\transfertEye.yaml, attempting download...\n",
      "Dataset download success  (0.0s), saved to \u001b[1mC:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\labeling_test\\datasets\\transfertEye.yaml\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'transfertEye.yaml' error  [WinError 3] Le chemin daccs spcifi est introuvable: 'C:\\\\Users\\\\matth\\\\OneDrive - ECAM\\\\Documents\\\\Cours ECAM\\\\5MIN\\\\Q1 23-24\\\\Projet IA\\\\labeling_test\\\\datasets\\\\transfertEye.yaml\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\engine\\trainer.py:114\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclassify\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m check_cls_dataset(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49mdata)\n\u001b[0;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39myaml\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myml\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mtask \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mdetect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msegment\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpose\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\data\\utils.py:377\u001b[0m, in \u001b[0;36mcheck_cls_dataset\u001b[1;34m(dataset, split)\u001b[0m\n\u001b[0;32m    376\u001b[0m nc \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (data_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mis_dir()])  \u001b[39m# number of classes\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m names \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (data_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39miterdir() \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mis_dir()]  \u001b[39m# class names list\u001b[39;00m\n\u001b[0;32m    378\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(\u001b[39msorted\u001b[39m(names)))\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\data\\utils.py:377\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    376\u001b[0m nc \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (data_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mis_dir()])  \u001b[39m# number of classes\u001b[39;00m\n\u001b[1;32m--> 377\u001b[0m names \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m (data_dir \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39miterdir() \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mis_dir()]  \u001b[39m# class names list\u001b[39;00m\n\u001b[0;32m    378\u001b[0m names \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39menumerate\u001b[39m(\u001b[39msorted\u001b[39m(names)))\n",
      "File \u001b[1;32mC:\\Python39\\lib\\pathlib.py:1149\u001b[0m, in \u001b[0;36mPath.iterdir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Iterate over the files in this directory.  Does not yield any\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[39mresult for the special paths '.' and '..'.\u001b[39;00m\n\u001b[0;32m   1148\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1149\u001b[0m \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mlistdir(\u001b[39mself\u001b[39;49m):\n\u001b[0;32m   1150\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m}:\n\u001b[0;32m   1151\u001b[0m         \u001b[39m# Yielding a path object for these makes little sense\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'C:\\\\Users\\\\matth\\\\OneDrive - ECAM\\\\Documents\\\\Cours ECAM\\\\5MIN\\\\Q1 23-24\\\\Projet IA\\\\labeling_test\\\\datasets\\\\transfertEye.yaml\\\\train'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\Transfert_learning_YOLO\\Transfert_learning.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/Transfert_learning_YOLO/Transfert_learning.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/Transfert_learning_YOLO/Transfert_learning.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain(data\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtransfertEye.yaml\u001b[39;49m\u001b[39m'\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, imgsz\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\engine\\model.py:333\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    331\u001b[0m     args[\u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path\n\u001b[1;32m--> 333\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m (trainer \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_smart_load(\u001b[39m'\u001b[39;49m\u001b[39mtrainer\u001b[39;49m\u001b[39m'\u001b[39;49m))(overrides\u001b[39m=\u001b[39;49margs, _callbacks\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallbacks)\n\u001b[0;32m    334\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mresume\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mget_model(weights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, cfg\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\models\\yolo\\classify\\train.py:39\u001b[0m, in \u001b[0;36mClassificationTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mif\u001b[39;00m overrides\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mimgsz\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     overrides[\u001b[39m'\u001b[39m\u001b[39mimgsz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m224\u001b[39m\n\u001b[1;32m---> 39\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(cfg, overrides, _callbacks)\n",
      "File \u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\venvFaceRecognition\\lib\\site-packages\\ultralytics\\engine\\trainer.py:120\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39myaml_file\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 120\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(emojis(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mclean_url(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdata)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m error ❌ \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtestset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n\u001b[0;32m    123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mema \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'transfertEye.yaml' error  [WinError 3] Le chemin daccs spcifi est introuvable: 'C:\\\\Users\\\\matth\\\\OneDrive - ECAM\\\\Documents\\\\Cours ECAM\\\\5MIN\\\\Q1 23-24\\\\Projet IA\\\\labeling_test\\\\datasets\\\\transfertEye.yaml\\\\train'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data='transfertEye.yaml', epochs=2, imgsz=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvFaceRecognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
