{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\face\\src\\facerec.cpp:61: error: (-2:Unspecified error) File can't be opened for reading! in function 'cv::face::FaceRecognizer::read'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\object_identification_face_recognition.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Load the model LBPH\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model_lbph \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mface\u001b[39m.\u001b[39mLBPHFaceRecognizer_create()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model_lbph\u001b[39m.\u001b[39;49mread(\u001b[39m\"\u001b[39;49m\u001b[39mLibrary/lbph_trained_model.yml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Load the image\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39mImages/face_recognition.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\face\\src\\facerec.cpp:61: error: (-2:Unspecified error) File can't be opened for reading! in function 'cv::face::FaceRecognizer::read'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import Library.package_face_recognition as fr\n",
    "import cv2\n",
    "import cv2.face\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Load the model YOLO\n",
    "model_YOLO = YOLO(\"Library/yolov8m.pt\")\n",
    "\n",
    "# Load the model LBPH\n",
    "\n",
    "model_lbph = cv2.face.LBPHFaceRecognizer_create()\n",
    "model_lbph.read(\"Library/lbph_trained_model.yml\")\n",
    "\n",
    "\n",
    "# Load the image\n",
    "\n",
    "image = cv2.imread(\"Images/face_recognition.jpg\")\n",
    "\n",
    "# Load the label dictionary\n",
    "label_dict = np.load('Library/label_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "# Detect the objects\n",
    "results = model_YOLO.predict(image)\n",
    "\n",
    "result = results[0]\n",
    "box = result.boxes[0]\n",
    "\n",
    "\n",
    "# if object is a person then crop the image and detect the face\n",
    "for i in range(len(result.boxes)):\n",
    "    box = result.boxes[i]\n",
    "    cords = box.xyxy[0].tolist()\n",
    "    cords = [round(x) for x in cords]\n",
    "    class_id = result.names[box.cls[0].item()]\n",
    "    conf = round(box.conf[0].item(), 2)\n",
    "\n",
    "    \n",
    "    if class_id == 'person':\n",
    "        print (\"person find : \",cords)\n",
    "        cropped_image = fr.cut_image(image, cords)\n",
    "        cv2.imwrite(f\"image_copped1{cords}.jpg\", cropped_image)\n",
    "\n",
    "        cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # cv2.imshow('cropped_image', cropped_image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        try:\n",
    "            label, coordinates = fr.face_recognition(cropped_image, model_lbph)\n",
    "\n",
    "            # find the corresponding name for the integer label\n",
    "            for name, l in label_dict.items():\n",
    "                if l == label:\n",
    "                    print(name)\n",
    "                    break\n",
    "            cords = coordinates + cords\n",
    "                    \n",
    "                    \n",
    "        except:\n",
    "            name= class_id\n",
    "            print(\"No face detected 2\")\n",
    "\n",
    "        \n",
    "  \n",
    "        \n",
    "        print (cords)\n",
    "        image = fr.boundary_Name_Box(image, name, cords)\n",
    "        # cv2.imshow('image', image)\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "Image.fromarray(result.plot()[:,:,::-1]).save('image.jpg')\n",
    "\n",
    "cv2.imwrite(\"image_label.jpg\", image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8.1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
