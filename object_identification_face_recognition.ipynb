{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Images/face_recognition.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matth\\OneDrive - ECAM\\Documents\\Cours ECAM\\5MIN\\Q1 23-24\\Projet IA\\AI_Identification_Face_Recognition\\object_identification_face_recognition.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model_lbph \u001b[39m=\u001b[39m YOLO(\u001b[39m\"\u001b[39m\u001b[39mLibrary/yolov8l.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Load the image\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(\u001b[39m\"\u001b[39;49m\u001b[39mImages/face_recognition.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# Detect the objects\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matth/OneDrive%20-%20ECAM/Documents/Cours%20ECAM/5MIN/Q1%2023-24/Projet%20IA/AI_Identification_Face_Recognition/object_identification_face_recognition.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m results \u001b[39m=\u001b[39m model_lbph\u001b[39m.\u001b[39mpredict(image)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\ultralytics\\utils\\patches.py:25\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(filename: \u001b[39mstr\u001b[39m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m cv2\u001b[39m.\u001b[39mimdecode(np\u001b[39m.\u001b[39;49mfromfile(filename, np\u001b[39m.\u001b[39;49muint8), flags)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Images/face_recognition.jpg'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import Library.package_face_recognition as fr\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model_lbph = YOLO(\"Library/yolov8l.pt\")\n",
    "\n",
    "# Load the image\n",
    "\n",
    "image = cv2.imread(\"Images/face_recognition.jpg\")\n",
    "\n",
    "# Detect the objects\n",
    "results = model_lbph.predict(image)\n",
    "\n",
    "result = results[0]\n",
    "box = result.boxes[0]\n",
    "\n",
    "\n",
    "# if object is a person then crop the image and detect the face\n",
    "for i in range(len(result.boxes)):\n",
    "    box = result.boxes[i]\n",
    "    cords = box.xyxy[0].tolist()\n",
    "    cords = [round(x) for x in cords]\n",
    "    class_id = result.names[box.cls[0].item()]\n",
    "    conf = round(box.conf[0].item(), 2)\n",
    "    if class_id == 'person':\n",
    "        cropped_image = fr.cut_image(image, cords)\n",
    "\n",
    "        # cropped_image = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "        cv2.imshow('cropped_image', cropped_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        try:\n",
    "            label, coordinates = fr.face_recognition(cropped_image, model_lbph)\n",
    "        except:\n",
    "            print(\"No face detected\")\n",
    "\n",
    "        # Load the label dictionary\n",
    "        label_dict = np.load('Library/label_dict.npy', allow_pickle=True).item()\n",
    "\n",
    "        # find the corresponding name for the integer label\n",
    "        for name, l in label_dict.items():\n",
    "            if l == label:\n",
    "                print(name)\n",
    "                break\n",
    "  \n",
    "\n",
    "        \n",
    "        image = fr.boundary_Name_Box(image, name, coordinates)\n",
    "        cv2.imshow('image', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
